{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP/62nrerLmhzjqjFFQMGX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shannonshih/Tibame_GAD245-Practice-HW_0319/blob/main/Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安裝所需模組"
      ],
      "metadata": {
        "id": "bF25ZasX61Fd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-mNklq96rT5",
        "outputId": "929a0f14-d8ef-412c-831a-5db099e273fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.40.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.8 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install protobuf --quiet\n",
        "!pip install numpy>=1.26.0 --quiet\n",
        "!pip install apache_beam==2.60.0 --quiet\n",
        "!pip install tensorflow==2.12.0 --quiet\n",
        "# To use the newly installed versions, restart the runtime.\n",
        "exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "授予GCP訪問權限"
      ],
      "metadata": {
        "id": "2Rx8nKRz6632"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "y3emqkMW67Nn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "導入模組並定義常數"
      ],
      "metadata": {
        "id": "N-y9cCzp7lRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from typing import Dict, Text, Any, Tuple, List\n",
        "import numpy\n",
        "\n",
        "from google.protobuf import text_format\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import apache_beam as beam\n",
        "from apache_beam.ml.inference.base import RunInference\n",
        "from apache_beam.ml.inference.base import KeyedModelHandler\n",
        "from apache_beam.ml.inference.tensorflow_inference import TFModelHandlerNumpy\n",
        "from apache_beam.ml.inference.tensorflow_inference import TFModelHandlerTensor\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "\n",
        "project = \"tibame-gad245-16-0319\"\n",
        "bucket = \"tibame-gad245-16-0319\"\n",
        "\n",
        "save_model_dir_multiply = f'gs://{bucket}/tf-inference/model/multiply_five/v1/'\n",
        "save_weights_dir_multiply = f'gs://{bucket}/tf-inference/weights/multiply_five/v1/'"
      ],
      "metadata": {
        "id": "VWlm76JV7lf7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立線性回歸模型"
      ],
      "metadata": {
        "id": "e6HvjCGh8JXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training data that represents the 5 times multiplication table for the numbers 0 to 99.\n",
        "# x is the data and y is the labels.\n",
        "x = numpy.arange(0, 100)   # Examples\n",
        "y = x * 5                  # Labels\n",
        "\n",
        "# Use create_model to build a simple linear regression model.\n",
        "# Note that the model has a shape of (1) for its input layer and expects a single int64 value.\n",
        "def create_model():\n",
        "  input_layer = keras.layers.Input(shape=(1), dtype=tf.float32, name='x')\n",
        "  output_layer= keras.layers.Dense(1)(input_layer)\n",
        "  model = keras.Model(input_layer, output_layer)\n",
        "  model.compile(optimizer=tf.optimizers.Adam(), loss='mean_absolute_error')\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg4RvJDJ8Jpr",
        "outputId": "7ce2a86b-142a-4692-f366-3bd510d79dbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " x (InputLayer)              [(None, 1)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "執行FIT"
      ],
      "metadata": {
        "id": "psqn9uds9hpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, epochs=500, verbose=0)\n",
        "test_examples =[20, 40, 60, 90]\n",
        "value_to_predict = numpy.array(test_examples, dtype=numpy.float32)\n",
        "predictions = model.predict(value_to_predict)\n",
        "\n",
        "print('Test Examples ' + str(test_examples))\n",
        "print('Predictions ' + str(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p75Mg-e9iHm",
        "outputId": "461a71ef-4ee6-444f-c5f0-5ba255367f3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n",
            "Test Examples [20, 40, 60, 90]\n",
            "Predictions [[ 49.79167]\n",
            " [ 97.58705]\n",
            " [145.38243]\n",
            " [217.07552]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "儲存模型"
      ],
      "metadata": {
        "id": "M2tBB0OV9zt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(save_model_dir_multiply)\n",
        "#model_handler = TFModelHandlerNumpy(path_to_weights, model_type=ModelType.SAVED_WEIGHTS, create_model_fn=build_tensorflow_model)\n",
        "model.save_weights(save_weights_dir_multiply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I83BdmlF9z_B",
        "outputId": "bb81b302-0153-4974-a104-485d9a84abc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "訓練模型預測"
      ],
      "metadata": {
        "id": "8chcgwsp_6Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FormatOutput(beam.DoFn):\n",
        "  def process(self, element, *args, **kwargs):\n",
        "     \"\"\"格式化推論結果輸出。\"\"\"\n",
        "     yield \"範例值為 {example}，預測結果為 {prediction}\".format(example=element.example, prediction=element.inference)\n",
        "\n",
        "# 建立輸入範例數據\n",
        "examples = numpy.array([20, 40, 60, 90], dtype=numpy.float32)\n",
        "\n",
        "# 設定 TensorFlow 模型處理器\n",
        "model_handler = TFModelHandlerNumpy(save_model_dir_multiply)\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    _ = (p\n",
        "         | \"建立輸入數據\" >> beam.Create(examples)\n",
        "         | \"執行模型推論\" >> RunInference(model_handler)\n",
        "         | \"格式化輸出結果\" >> beam.ParDo(FormatOutput())\n",
        "         | \"輸出結果\" >> beam.Map(print)\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "3C9HZKip_6ob",
        "outputId": "f4a00cad-00f8-4698-8354-3488816b8153"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "範例值為 20.0，預測結果為 [49.79167]\n",
            "範例值為 40.0，預測結果為 [97.58705]\n",
            "範例值為 60.0，預測結果為 [145.38243]\n",
            "範例值為 90.0，預測結果為 [217.07552]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "加入權重預測"
      ],
      "metadata": {
        "id": "ihEfGbylAmU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from apache_beam.ml.inference.tensorflow_inference import ModelType\n",
        "\n",
        "# 建立輸入範例數據\n",
        "examples = numpy.array([20, 40, 60, 90], dtype=numpy.float32)\n",
        "\n",
        "# 設定 TensorFlow 模型處理器，使用儲存的權重進行推論\n",
        "model_handler = TFModelHandlerNumpy(\n",
        "    save_weights_dir_multiply,\n",
        "    model_type=ModelType.SAVED_WEIGHTS,\n",
        "    create_model_fn=create_model\n",
        ")\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    _ = (p\n",
        "         | \"建立輸入數據\" >> beam.Create(examples)\n",
        "         | \"執行模型推論\" >> RunInference(model_handler)\n",
        "         | \"格式化輸出結果\" >> beam.ParDo(FormatOutput())\n",
        "         | \"輸出結果\" >> beam.Map(print)\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAKz-7O3Amkl",
        "outputId": "560e1fe1-b0d0-4901-caea-a131adcd5e0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "範例值為 20.0，預測結果為 [49.79167]\n",
            "範例值為 40.0，預測結果為 [97.58705]\n",
            "範例值為 60.0，預測結果為 [145.38243]\n",
            "範例值為 90.0，預測結果為 [217.07552]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "鍵值資料預測"
      ],
      "metadata": {
        "id": "Cse5yzsZDPm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FormatOutputKeyed(FormatOutput):\n",
        "  # 繼承自 FormatOutput。\n",
        "  def process(self, tuple_in: Tuple):\n",
        "    key, element = tuple_in\n",
        "    output = super().process(element)\n",
        "    yield \"{} : {}\".format(key, [op for op in output])\n",
        "\n",
        "# 建立輸入範例數據（包含鍵值）\n",
        "examples = numpy.array([(1, 20), (2, 40), (3, 60), (4, 90)], dtype=numpy.float32)\n",
        "\n",
        "# 設定鍵值模型處理器\n",
        "keyed_model_handler = KeyedModelHandler(TFModelHandlerNumpy(save_model_dir_multiply))\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "    _ = (p\n",
        "         | \"建立輸入數據\" >> beam.Create(examples)\n",
        "         | \"執行模型推論\" >> RunInference(keyed_model_handler)\n",
        "         | \"格式化輸出結果（含鍵值）\" >> beam.ParDo(FormatOutputKeyed())\n",
        "         | \"輸出結果\" >> beam.Map(print)\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKyjG8uuDP09",
        "outputId": "3cb76047-978b-434c-f9f2-ab87fae5ab46"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 : ['範例值為 20.0，預測結果為 [49.79167]']\n",
            "2.0 : ['範例值為 40.0，預測結果為 [97.58705]']\n",
            "3.0 : ['範例值為 60.0，預測結果為 [145.38243]']\n",
            "4.0 : ['範例值為 90.0，預測結果為 [217.07552]']\n"
          ]
        }
      ]
    }
  ]
}