{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtvmMekVzzRuffm2u5kD/V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shannonshih/Tibame_GAD245-Practice-HW_0319/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安裝Dataflow的SDK模組"
      ],
      "metadata": {
        "id": "ujbiVKJMNTIU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frWl6mw4JZLy",
        "outputId": "d88de8f0-482c-47d2-bb1b-719f64e6b335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.5/274.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install apache_beam[gcp,dataframe] --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安裝 PyTorch 模組"
      ],
      "metadata": {
        "id": "iWMf2P7uNRRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSHAajvqJ69F",
        "outputId": "a4824a7b-e065-424b-d09b-773e093f957c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "導入實驗所虛模組"
      ],
      "metadata": {
        "id": "S13-KEjyNPNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "from typing import Tuple\n",
        "\n",
        "import apache_beam as beam\n",
        "import numpy\n",
        "from apache_beam.io.gcp.bigquery import ReadFromBigQuery\n",
        "from apache_beam.ml.inference.base import KeyedModelHandler\n",
        "from apache_beam.ml.inference.base import PredictionResult\n",
        "from apache_beam.ml.inference.base import RunInference\n",
        "from apache_beam.dataframe.convert import to_pcollection\n",
        "from apache_beam.ml.inference.pytorch_inference import PytorchModelHandlerTensor\n",
        "from apache_beam.ml.inference.pytorch_inference import PytorchModelHandlerKeyedTensor\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "tMUoPxP4L1er"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "授予Colab筆記本訪問管理GCP權限"
      ],
      "metadata": {
        "id": "grMjy3fpNLGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "tsFPqg3yM9XA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定義GCP使用的專案及值區"
      ],
      "metadata": {
        "id": "o9_Fm6ieNVEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義常數（Constants）\n",
        "project = \"tibame-gad245-16-0319\"\n",
        "bucket = \"tibame-gad245-16-0319\"  # 儲存桶 ID\n",
        "\n",
        "# 設定專案 ID。\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = project\n",
        "\n",
        "# 儲存模型的路徑\n",
        "save_model_dir_multiply_five = 'five_times_table_torch.pt'\n",
        "save_model_dir_multiply_ten = 'ten_times_table_torch.pt'"
      ],
      "metadata": {
        "id": "syFNIYfIOC-b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立線性迴歸模型"
      ],
      "metadata": {
        "id": "aurCyDqEQImi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim=1, output_dim=1):\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "E_91ObXGQI4Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "準備測試資料確認模型狀況"
      ],
      "metadata": {
        "id": "tt6vjqzIQPqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = numpy.arange(0, 100, dtype=numpy.float32).reshape(-1, 1)\n",
        "y = (x * 5).reshape(-1, 1)\n",
        "value_to_predict = numpy.array([20, 40, 60, 90], dtype=numpy.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "fwnd-laOQRIg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "測試Pytorch模型狀況_訓練five time模型"
      ],
      "metadata": {
        "id": "A65l9nkqQU2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "five_times_model = LinearRegression()\n",
        "optimizer = torch.optim.Adam(five_times_model.parameters())\n",
        "loss_fn = torch.nn.L1Loss()\n",
        "\n",
        "\"\"\"\n",
        "Train the five_times_model\n",
        "\"\"\"\n",
        "epochs = 10000\n",
        "tensor_x = torch.from_numpy(x)\n",
        "tensor_y = torch.from_numpy(y)\n",
        "for epoch in range(epochs):\n",
        "    y_pred = five_times_model(tensor_x)\n",
        "    loss = loss_fn(y_pred, tensor_y)\n",
        "    five_times_model.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "aJLP9J_YQYRi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用torch.save()儲存模型_five time模型"
      ],
      "metadata": {
        "id": "5H_ENbWqRIfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(five_times_model.state_dict(), save_model_dir_multiply_five)\n",
        "print(os.path.exists(save_model_dir_multiply_five)) # Verify that the model is saved."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmhl674JRICi",
        "outputId": "7a166f36-e024-450a-9712-a1b6da424ba0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "設定ten time模型參數"
      ],
      "metadata": {
        "id": "sma8DseLSNeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = numpy.arange(0, 100, dtype=numpy.float32).reshape(-1, 1)\n",
        "y = (x * 10).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "E-9gLwS0SQeR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "測試10 time資料"
      ],
      "metadata": {
        "id": "1SmwRRVhRMc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ten_times_model = LinearRegression()\n",
        "optimizer = torch.optim.Adam(ten_times_model.parameters())\n",
        "loss_fn = torch.nn.L1Loss()\n",
        "\n",
        "epochs = 10000\n",
        "tensor_x = torch.from_numpy(x)\n",
        "tensor_y = torch.from_numpy(y)\n",
        "for epoch in range(epochs):\n",
        "    y_pred = ten_times_model(tensor_x)\n",
        "    loss = loss_fn(y_pred, tensor_y)\n",
        "    ten_times_model.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "5TsbcAUhRO4Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "儲存模型_ten time模型"
      ],
      "metadata": {
        "id": "fsX8lrdARaZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(ten_times_model.state_dict(), save_model_dir_multiply_ten)\n",
        "print(os.path.exists(save_model_dir_multiply_ten)) # verify if the model is saved"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5zgb0tSSaiW",
        "outputId": "f5a03079-77f1-4a73-ddf3-ee3c04361158"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立預測管道"
      ],
      "metadata": {
        "id": "iixj846WS--p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_five_times_model_handler = PytorchModelHandlerTensor(\n",
        "    state_dict_path=save_model_dir_multiply_five,\n",
        "    model_class=LinearRegression,\n",
        "    model_params={'input_dim': 1,\n",
        "                  'output_dim': 1}\n",
        "                  )\n",
        "pipeline = beam.Pipeline()\n",
        "\n",
        "with pipeline as p:\n",
        "      (\n",
        "      p\n",
        "      | \"ReadInputData\" >> beam.Create(value_to_predict)\n",
        "      | \"ConvertNumpyToTensor\" >> beam.Map(torch.Tensor)\n",
        "      | \"RunInferenceTorch\" >> RunInference(torch_five_times_model_handler)\n",
        "      | beam.Map(print)\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "-56qkZY7S_Yx",
        "outputId": "f0354854-3efa-4191-f383-f18ca63d14f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PredictionResult(example=tensor([20.]), inference=tensor([100.6086]), model_id='five_times_table_torch.pt')\n",
            "PredictionResult(example=tensor([40.]), inference=tensor([200.3650]), model_id='five_times_table_torch.pt')\n",
            "PredictionResult(example=tensor([60.]), inference=tensor([300.1214]), model_id='five_times_table_torch.pt')\n",
            "PredictionResult(example=tensor([90.]), inference=tensor([449.7559]), model_id='five_times_table_torch.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "取出並處理管道輸出結果"
      ],
      "metadata": {
        "id": "aiB7rnTLThpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PredictionProcessor(beam.DoFn):\n",
        "  \"\"\"\n",
        "  用於格式化 RunInference 轉換輸出的處理器。\n",
        "  \"\"\"\n",
        "  def process(\n",
        "      self,\n",
        "      element: PredictionResult):\n",
        "    input_value = element.example\n",
        "    output_value = element.inference\n",
        "    yield (f\"輸入值為 {input_value.item()}，輸出值為 {output_value.item()}\")\n",
        "\n",
        "pipeline = beam.Pipeline()\n",
        "\n",
        "with pipeline as p:\n",
        "    (\n",
        "    p\n",
        "    | \"讀取輸入資料\" >> beam.Create(value_to_predict)\n",
        "    | \"將 Numpy 轉換為 Tensor\" >> beam.Map(torch.Tensor)\n",
        "    | \"執行 Torch 推論\" >> RunInference(torch_five_times_model_handler)\n",
        "    | \"後處理預測結果\" >> beam.ParDo(PredictionProcessor())\n",
        "    | beam.Map(print)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8pAU-WjTiAm",
        "outputId": "4d63f9ba-8625-4f88-db55-e595b04b0834"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "輸入值為 20.0，輸出值為 100.6086196899414\n",
            "輸入值為 40.0，輸出值為 200.364990234375\n",
            "輸入值為 60.0，輸出值為 300.1213684082031\n",
            "輸入值為 90.0，輸出值為 449.75592041015625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "定義鍵值資料格式"
      ],
      "metadata": {
        "id": "J5WFCyEYWYlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PredictionWithKeyProcessor(beam.DoFn):\n",
        "    def __init__(self):\n",
        "        beam.DoFn.__init__(self)\n",
        "\n",
        "    def process(\n",
        "          self,\n",
        "          element: Tuple[str, PredictionResult]):\n",
        "        key = element[0]\n",
        "        input_value = element[1].example\n",
        "        output_value = element[1].inference\n",
        "        yield (f\"key: {key}, input: {input_value.item()} output: {output_value.item()}\" )"
      ],
      "metadata": {
        "id": "FJgGaUWmWY5C"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "更新BigQuery模組"
      ],
      "metadata": {
        "id": "AaMEk0oDWzC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade google-cloud-bigquery --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktL013MgWzUo",
        "outputId": "fcab2327-489d-477f-8ee8-dfa45cd4a7da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m245.8/247.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.9/247.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "設定專案指向"
      ],
      "metadata": {
        "id": "vX-XCh-tXATk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project $project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqNX8LC0XAft",
        "outputId": "d941d113-7f45-4694-9bfc-935580cf9b3d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "透過BigQuery SDK建立資料及和資料表"
      ],
      "metadata": {
        "id": "eSJC9HDaXMbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "client = bigquery.Client(project=project)\n",
        "\n",
        "# 確保 dataset_id 在專案中是唯一的。\n",
        "dataset_id = '{project}.maths'.format(project=project)\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "\n",
        "# 根據專案配置修改位置。\n",
        "dataset.location = 'US'\n",
        "dataset = client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "# BigQuery 資料集中的資料表名稱。\n",
        "table_name = 'maths_problems_1'\n",
        "\n",
        "query = \"\"\"\n",
        "    CREATE OR REPLACE TABLE\n",
        "      {project}.maths.{table} ( key STRING OPTIONS(description=\"A unique key for the maths problem\"),\n",
        "    value FLOAT64 OPTIONS(description=\"Our maths problem\" ) );\n",
        "    INSERT INTO maths.{table}\n",
        "    VALUES\n",
        "      (\"first_question\", 105.00),\n",
        "      (\"second_question\", 108.00),\n",
        "      (\"third_question\", 1000.00),\n",
        "      (\"fourth_question\", 1013.00)\n",
        "\"\"\".format(project=project, table=table_name)\n",
        "\n",
        "create_job = client.query(query)\n",
        "create_job.result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z71vCI6sXMti",
        "outputId": "191d1e32-50cd-4883-dbd2-ce81f6d54354"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ca4f09b46d0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "從BigQuery抓取資料預測"
      ],
      "metadata": {
        "id": "b0adskI2Yhzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_options = PipelineOptions().from_dictionary({'temp_location':f'gs://{bucket}/tmp',\n",
        "                                                      })\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "keyed_torch_five_times_model_handler = KeyedModelHandler(torch_five_times_model_handler)\n",
        "\n",
        "table_name = 'maths_problems_1'\n",
        "table_spec = f'{project}:maths.{table_name}'\n",
        "\n",
        "with pipeline as p:\n",
        "      (\n",
        "      p\n",
        "      | \"ReadFromBQ\" >> beam.io.ReadFromBigQuery(table=table_spec)\n",
        "      | \"PreprocessData\" >> beam.Map(lambda x: (x['key'], x['value']))\n",
        "      | \"ConvertNumpyToTensor\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "      | \"RunInferenceTorch\" >> RunInference(keyed_torch_five_times_model_handler)\n",
        "      | \"PostProcessPredictions\" >> beam.ParDo(PredictionWithKeyProcessor())\n",
        "      | beam.Map(print)\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5PBW82nYhVv",
        "outputId": "e918c4f4-c8c7-47cb-cc73-cbb635d74fbe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key: fourth_question, input: 1013.0 output: 5053.51220703125\n",
            "key: second_question, input: 108.0 output: 539.5366821289062\n",
            "key: first_question, input: 105.0 output: 524.5731811523438\n",
            "key: third_question, input: 1000.0 output: 4988.6708984375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立CSV檔案"
      ],
      "metadata": {
        "id": "rqfS67MUY7bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立CSV範例資料\n",
        "csv_values = [(\"first_question\", 105.00),\n",
        "      (\"second_question\", 108.00),\n",
        "      (\"third_question\", 1000.00),\n",
        "      (\"fourth_question\", 1013.00)]\n",
        "input_csv_file = \"./maths_problem.csv\"\n",
        "\n",
        "with open(input_csv_file, 'w') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(['key', 'value'])\n",
        "  for row in csv_values:\n",
        "    writer.writerow(row)\n",
        "\n",
        "assert os.path.exists(input_csv_file) == True"
      ],
      "metadata": {
        "id": "6zKeab72Y-zO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "抓取CSV檔資料進行預測"
      ],
      "metadata": {
        "id": "xDE5Xl2aaoxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_options = PipelineOptions().from_dictionary({'temp_location':f'gs://{bucket}/tmp',\n",
        "                                                      })\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "keyed_torch_five_times_model_handler = KeyedModelHandler(torch_five_times_model_handler)\n",
        "\n",
        "with pipeline as p:\n",
        "  df = p | beam.dataframe.io.read_csv(input_csv_file)\n",
        "  pc = to_pcollection(df)\n",
        "  (pc\n",
        "    | \"ConvertNumpyToTensor\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "    | \"RunInferenceTorch\" >> RunInference(keyed_torch_five_times_model_handler)\n",
        "    | \"PostProcessPredictions\" >> beam.ParDo(PredictionWithKeyProcessor())\n",
        "    | beam.Map(print)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhipX_MrapAC",
        "outputId": "1fade8c4-99be-49e0-ee5e-452445047910"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key: first_question, input: 105.0 output: 524.5731811523438\n",
            "key: second_question, input: 108.0 output: 539.5366821289062\n",
            "key: third_question, input: 1000.0 output: 4988.6708984375\n",
            "key: fourth_question, input: 1013.0 output: 5053.51220703125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "一管道多模型資源預測"
      ],
      "metadata": {
        "id": "bkA1rw_Aa4-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_ten_times_model_handler = PytorchModelHandlerTensor(state_dict_path=save_model_dir_multiply_ten,\n",
        "                                        model_class=LinearRegression,\n",
        "                                        model_params={'input_dim': 1,\n",
        "                                                      'output_dim': 1}\n",
        "                                        )\n",
        "keyed_torch_ten_times_model_handler = KeyedModelHandler(torch_ten_times_model_handler)"
      ],
      "metadata": {
        "id": "gPyBc31fa5LP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "建立管道抓取多模型預測"
      ],
      "metadata": {
        "id": "8VsOv0trbtGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_options = PipelineOptions().from_dictionary(\n",
        "                                      {'temp_location':f'gs://{bucket}/tmp'})\n",
        "\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "read_from_bq = beam.io.ReadFromBigQuery(table=table_spec)\n",
        "\n",
        "with pipeline as p:\n",
        "  multiply_five = (\n",
        "      p\n",
        "      |  read_from_bq\n",
        "      | \"CreateMultiplyFiveTuple\" >> beam.Map(lambda x: ('{} {}'.format(x['key'], '* 5'), x['value']))\n",
        "      | \"ConvertNumpyToTensorFiveTuple\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "      | \"RunInferenceTorchFiveTuple\" >> RunInference(keyed_torch_five_times_model_handler)\n",
        "  )\n",
        "  multiply_ten = (\n",
        "      p\n",
        "      | read_from_bq\n",
        "      | \"CreateMultiplyTenTuple\" >> beam.Map(lambda x: ('{} {}'.format(x['key'], '* 10'), x['value']))\n",
        "      | \"ConvertNumpyToTensorTenTuple\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "      | \"RunInferenceTorchTenTuple\" >> RunInference(keyed_torch_ten_times_model_handler)\n",
        "  )\n",
        "\n",
        "  inference_result = ((multiply_five, multiply_ten) | beam.Flatten()\n",
        "                                 | beam.ParDo(PredictionWithKeyProcessor()))\n",
        "  inference_result | beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZixhhMRbtWv",
        "outputId": "8559c136-a385-48b0-9608-ed3c65ff281c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n",
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key: fourth_question * 5, input: 1013.0 output: 5053.51220703125\n",
            "key: second_question * 5, input: 108.0 output: 539.5366821289062\n",
            "key: first_question * 5, input: 105.0 output: 524.5731811523438\n",
            "key: third_question * 5, input: 1000.0 output: 4988.6708984375\n",
            "key: fourth_question * 10, input: 1013.0 output: 9924.328125\n",
            "key: second_question * 10, input: 108.0 output: 1067.43896484375\n",
            "key: first_question * 10, input: 105.0 output: 1038.0791015625\n",
            "key: third_question * 10, input: 1000.0 output: 9797.1015625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "依序多模型管道預測"
      ],
      "metadata": {
        "id": "z7soPznZcQ7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_interim_inference(element):\n",
        "    key, prediction_result = element\n",
        "    input_value = prediction_result.example\n",
        "    inference = prediction_result.inference\n",
        "    formatted_input_value = 'original input is `{} {}`'.format(key, input_value)\n",
        "    return formatted_input_value, inference\n",
        "\n",
        "\n",
        "pipeline_options = PipelineOptions().from_dictionary(\n",
        "                                      {'temp_location':f'gs://{bucket}/tmp'})\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "with pipeline as p:\n",
        "  multiply_five = (\n",
        "      p\n",
        "      | beam.io.ReadFromBigQuery(table=table_spec)\n",
        "      | \"CreateMultiplyFiveTuple\" >> beam.Map(lambda x: (x['key'], x['value']))\n",
        "      | \"ConvertNumpyToTensorFiveTuple\" >> beam.Map(lambda x: (x[0], torch.Tensor([x[1]])))\n",
        "      | \"RunInferenceTorchFiveTuple\" >> RunInference(keyed_torch_five_times_model_handler)\n",
        "  )\n",
        "\n",
        "  inference_result = (\n",
        "    multiply_five\n",
        "      | \"ExtractResult\" >> beam.Map(process_interim_inference)\n",
        "      | \"RunInferenceTorchTenTuple\" >> RunInference(keyed_torch_ten_times_model_handler)\n",
        "      | beam.ParDo(PredictionWithKeyProcessor())\n",
        "    )\n",
        "  inference_result | beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foCygx7LcVsg",
        "outputId": "f0bf6c47-bc46-4f15-d6fe-fb07019a8389"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.transforms.core:('No iterator is returned by the process method in %s.', <class 'apache_beam.io.gcp.bigquery_read_internal._PassThroughThenCleanup.expand.<locals>.RemoveExtractedFiles'>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key: original input is `fourth_question tensor([1013.])`, input: 5053.51220703125 output: 49467.2734375\n",
            "key: original input is `second_question tensor([108.])`, input: 539.5366821289062 output: 5290.7236328125\n",
            "key: original input is `first_question tensor([105.])`, input: 524.5731811523438 output: 5144.28125\n",
            "key: original input is `third_question tensor([1000.])`, input: 4988.6708984375 output: 48832.6953125\n"
          ]
        }
      ]
    }
  ]
}